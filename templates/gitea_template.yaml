---
# Source: gitea/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  postgres-password: "eGNvb0Qyd2J4NQ=="
  password: "Z2l0ZWE="
---
# Source: gitea/templates/gitea/config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-gitea-inline-config
  labels:
    helm.sh/chart: gitea-8.3.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.19.3"
    version: "1.19.3"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  _generals_: ""
  cache: |-
    ADAPTER=memcache
    ENABLED=true
    HOST=release-name-memcached.default.svc.cluster.local:11211
  database: |-
    DB_TYPE=postgres
    HOST=release-name-postgresql.default.svc.cluster.local:5432
    NAME=gitea
    PASSWD=gitea
    USER=gitea
  metrics: ENABLED=false
  repository: ROOT=/data/git/gitea-repositories
  security: INSTALL_LOCK=true
  server: |-
    APP_DATA_PATH=/data
    DOMAIN=git.example.com
    ENABLE_PPROF=false
    HTTP_PORT=3000
    PROTOCOL=http
    ROOT_URL=http://git.example.com
    SSH_DOMAIN=git.example.com
    SSH_LISTEN_PORT=22
    SSH_PORT=22
---
# Source: gitea/templates/gitea/config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-gitea
  labels:
    helm.sh/chart: gitea-8.3.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.19.3"
    version: "1.19.3"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  config_environment.sh: |-
    #!/usr/bin/env bash
    set -euo pipefail

    function env2ini::log() {
      printf "${1}\n"
    }

    function env2ini::read_config_to_env() {
      local section="${1}"
      local line="${2}"

      if [[ -z "${line}" ]]; then
        # skip empty line
        return
      fi
      
      # 'xargs echo -n' trims all leading/trailing whitespaces and a trailing new line
      local setting="$(awk -F '=' '{print $1}' <<< "${line}" | xargs echo -n)"

      if [[ -z "${setting}" ]]; then
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      local value=''
      local regex="^${setting}(\s*)=(\s*)(.*)"
      if [[ $line =~ $regex ]]; then
        value="${BASH_REMATCH[3]}"
      else
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      env2ini::log "    + '${setting}'"

      if [[ -z "${section}" ]]; then
        export "ENV_TO_INI____${setting^^}=${value}"                           # '^^' makes the variable content uppercase
        return
      fi

      local masked_section="${section//./_0X2E_}"                            # '//' instructs to replace all matches
      masked_section="${masked_section//-/_0X2D_}"

      export "ENV_TO_INI__${masked_section^^}__${setting^^}=${value}"        # '^^' makes the variable content uppercase
    }

    function env2ini::reload_preset_envs() {
      env2ini::log "Reloading preset envs..."

      while read -r line; do
        if [[ -z "${line}" ]]; then
          # skip empty line
          return
        fi

        # 'xargs echo -n' trims all leading/trailing whitespaces and a trailing new line
        local setting="$(awk -F '=' '{print $1}' <<< "${line}" | xargs echo -n)"

        if [[ -z "${setting}" ]]; then
          env2ini::log '  ! invalid setting'
          exit 1
        fi

        local value=''
        local regex="^${setting}(\s*)=(\s*)(.*)"
        if [[ $line =~ $regex ]]; then
          value="${BASH_REMATCH[3]}"
        else
          env2ini::log '  ! invalid setting'
          exit 1
        fi

        env2ini::log "  + '${setting}'"

        export "${setting^^}=${value}"                           # '^^' makes the variable content uppercase
      done < "/tmp/existing-envs"

      rm /tmp/existing-envs
    }


    function env2ini::process_config_file() {
      local config_file="${1}"
      local section="$(basename "${config_file}")"

      if [[ $section == '_generals_' ]]; then
        env2ini::log "  [ini root]"
        section=''
      else
        env2ini::log "  ${section}"
      fi

      while read -r line; do
        env2ini::read_config_to_env "${section}" "${line}"
      done < <(awk 1 "${config_file}")                             # Helm .toYaml trims the trailing new line which breaks line processing; awk 1 ... adds it back while reading
    }

    function env2ini::load_config_sources() {
      local path="${1}"

      if [[ -d "${path}" ]]; then
        env2ini::log "Processing $(basename "${path}")..."

        while read -d '' configFile; do
          env2ini::process_config_file "${configFile}"
        done < <(find "${path}" -type l -not -name '..data' -print0)

        env2ini::log "\n"
      fi
    }

    function env2ini::generate_initial_secrets() {
      # These environment variables will either be
      #   - overwritten with user defined values,
      #   - initially used to set up Gitea
      # Anyway, they won't harm existing app.ini files

      export ENV_TO_INI__SECURITY__INTERNAL_TOKEN=$(gitea generate secret INTERNAL_TOKEN)
      export ENV_TO_INI__SECURITY__SECRET_KEY=$(gitea generate secret SECRET_KEY)
      export ENV_TO_INI__OAUTH2__JWT_SECRET=$(gitea generate secret JWT_SECRET)
      export ENV_TO_INI__SERVER__LFS_JWT_SECRET=$(gitea generate secret LFS_JWT_SECRET)

      env2ini::log "...Initial secrets generated\n"
    }

    env | (grep ENV_TO_INI || [[ $? == 1 ]]) > /tmp/existing-envs
    
    # MUST BE CALLED BEFORE OTHER CONFIGURATION
    env2ini::generate_initial_secrets

    env2ini::load_config_sources '/env-to-ini-mounts/inlines/'
    env2ini::load_config_sources '/env-to-ini-mounts/additionals/'

    # load existing envs to override auto generated envs
    env2ini::reload_preset_envs

    env2ini::log "=== All configuration sources loaded ===\n"

    # safety to prevent rewrite of secret keys if an app.ini already exists
    if [ -f ${GITEA_APP_INI} ]; then
      env2ini::log 'An app.ini file already exists. To prevent overwriting secret keys, these settings are dropped and remain unchanged:'
      env2ini::log '  - security.INTERNAL_TOKEN'
      env2ini::log '  - security.SECRET_KEY'
      env2ini::log '  - oauth2.JWT_SECRET'
      env2ini::log '  - server.LFS_JWT_SECRET'

      unset ENV_TO_INI__SECURITY__INTERNAL_TOKEN
      unset ENV_TO_INI__SECURITY__SECRET_KEY
      unset ENV_TO_INI__OAUTH2__JWT_SECRET
      unset ENV_TO_INI__SERVER__LFS_JWT_SECRET
    fi

    environment-to-ini -o $GITEA_APP_INI -p ENV_TO_INI
---
# Source: gitea/templates/gitea/init.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-gitea-init
  labels:
    helm.sh/chart: gitea-8.3.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.19.3"
    version: "1.19.3"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  configure_gpg_environment.sh: |-
    #!/usr/bin/env bash
    set -eu

    gpg --batch --import /raw/private.asc
  init_directory_structure.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail

    set -x
    chown 1000:1000 /data
    mkdir -p /data/git/.ssh
    chmod -R 700 /data/git/.ssh
    [ ! -d /data/gitea/conf ] && mkdir -p /data/gitea/conf

    # prepare temp directory structure
    mkdir -p "${GITEA_TEMP}"
    chown 1000:1000 "${GITEA_TEMP}"
    chmod ug+rwx "${GITEA_TEMP}"

    

  configure_gitea.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail

    echo '==== BEGIN GITEA CONFIGURATION ===='

    { # try
      gitea migrate
    } || { # catch
      echo "Gitea migrate might fail due to database connection...This init-container will try again in a few seconds"
      exit 1
    }
    function configure_admin_user() {
      local ACCOUNT_ID=$(gitea admin user list --admin | grep -e "\s\+${GITEA_ADMIN_USERNAME}\s\+" | awk -F " " "{printf \$1}")
      if [[ -z "${ACCOUNT_ID}" ]]; then
        echo "No admin user '${GITEA_ADMIN_USERNAME}' found. Creating now..."
        gitea admin user create --admin --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}" --email "gitea@local.domain" --must-change-password=false
        echo '...created.'
      else
        echo "Admin account '${GITEA_ADMIN_USERNAME}' already exist. Running update to sync password..."
        gitea admin user change-password --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}"
        echo '...password sync done.'
      fi
    }

    configure_admin_user

    function configure_ldap() {
        echo 'no ldap configuration... skipping.'
    }

    configure_ldap

    function configure_oauth() {
        echo 'no oauth configuration... skipping.'
    }

    configure_oauth

    echo '==== END GITEA CONFIGURATION ===='
---
# Source: gitea/charts/memcached/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-memcached
  namespace: default
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-6.3.14
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: memcache
      port: 11211
      targetPort: memcache
      nodePort: null
  selector:
    app.kubernetes.io/name: memcached
    app.kubernetes.io/instance: release-name
---
# Source: gitea/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql-hl
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: primary
---
# Source: gitea/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: primary
---
# Source: gitea/templates/gitea/http-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-gitea-http
  labels:
    helm.sh/chart: gitea-8.3.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.19.3"
    version: "1.19.3"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: http
    port: 3000
    targetPort: 3000
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: release-name
---
# Source: gitea/templates/gitea/ssh-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-gitea-ssh
  labels:
    helm.sh/chart: gitea-8.3.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.19.3"
    version: "1.19.3"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: ssh
    port: 22
    targetPort: 22
    protocol: TCP
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: release-name
---
# Source: gitea/charts/memcached/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-memcached
  namespace: default
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-6.3.14
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: memcached
      app.kubernetes.io/instance: release-name
  replicas: 1
  strategy:
    rollingUpdate: {}
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: memcached
        helm.sh/chart: memcached-6.3.14
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
      annotations:
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: memcached
                    app.kubernetes.io/instance: release-name
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
      securityContext:
        fsGroup: 1001
      containers:
        - name: memcached
          image: docker.io/bitnami/memcached:1.6.19-debian-11-r7
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MEMCACHED_PORT_NUMBER
              value: "11211"
          ports:
            - name: memcache
              containerPort: 11211
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            tcpSocket:
              port: memcache
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
            tcpSocket:
              port: memcache
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: gitea/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.4.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: release-name-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: release-name-postgresql
      labels:
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-12.4.1
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: primary
    spec:
      affinity:
        podAffinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
      securityContext:
        fsGroup: 1001
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:15.2.0-debian-11-r26
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "gitea"
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: postgres-password
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: password
            - name: POSTGRES_DB
              value: "gitea"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "gitea" -d "dbname=gitea" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                
                - |
                  exec pg_isready -U "gitea" -d "dbname=gitea" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "10Gi"
---
# Source: gitea/templates/gitea/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-gitea
  annotations:
  labels:
    helm.sh/chart: gitea-8.3.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.19.3"
    version: "1.19.3"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: gitea
      app.kubernetes.io/instance: release-name
  serviceName: release-name-gitea
  template:
    metadata:
      annotations:
        checksum/config: 16ee04567b54155f5ccc612683a37fffce14728cd3f5fc615330f310d8fca043
      labels:
        helm.sh/chart: gitea-8.3.0
        app: gitea
        app.kubernetes.io/name: gitea
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "1.19.3"
        version: "1.19.3"
        app.kubernetes.io/managed-by: Helm
    spec:
      securityContext:
        fsGroup: 1000
      initContainers:
        - name: init-directories
          image: "gitea/gitea:1.19.3"
          imagePullPolicy: Always
          command: ["/usr/sbin/init_directory_structure.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
          securityContext:
            {}
          resources:
            limits: {}
            requests:
              cpu: 100m
              memory: 128Mi
        - name: init-app-ini
          image: "gitea/gitea:1.19.3"
          imagePullPolicy: Always
          command: ["/usr/sbin/config_environment.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
          volumeMounts:
            - name: config
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
            - name: inline-config-sources
              mountPath: /env-to-ini-mounts/inlines/
          securityContext:
            {}
          resources:
            limits: {}
            requests:
              cpu: 100m
              memory: 128Mi
        - name: configure-gitea
          image: "gitea/gitea:1.19.3"
          command: ["/usr/sbin/configure_gitea.sh"]
          imagePullPolicy: Always
          securityContext:
            runAsUser: 1000
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: GITEA_ADMIN_USERNAME
              value: "gitea_admin"
            - name: GITEA_ADMIN_PASSWORD
              value: "r8sA8CPHD9!bt6d"
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
          resources:
            limits: {}
            requests:
              cpu: 100m
              memory: 128Mi
      terminationGracePeriodSeconds: 60
      containers:
        - name: gitea
          image: "gitea/gitea:1.19.3"
          imagePullPolicy: Always
          env:
            # SSH Port values have to be set here as well for openssh configuration
            - name: SSH_LISTEN_PORT
              value: "22"
            - name: SSH_PORT
              value: "22"
            - name: SSH_LOG_LEVEL
              value: "INFO"
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: TMPDIR
              value: /tmp/gitea
          ports:
            - name: ssh
              containerPort: 22
            - name: http
              containerPort: 3000
          livenessProbe:
            failureThreshold: 10
            initialDelaySeconds: 200
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: http
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: http
            timeoutSeconds: 1
          resources:
            {}
          securityContext:
            {}
          volumeMounts:
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
            
      volumes:
        - name: init
          secret:
            secretName: release-name-gitea-init
            defaultMode: 110
        - name: config
          secret:
            secretName: release-name-gitea
            defaultMode: 110
        - name: inline-config-sources
          secret:
            secretName: release-name-gitea-inline-config
        - name: temp
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
            - "ReadWriteOnce"        
        resources:
          requests:
            storage: "10Gi"
---
# Source: gitea/templates/tests/test-http-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "release-name-gitea-test-connection"
  labels:
    helm.sh/chart: gitea-8.3.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.19.3"
    version: "1.19.3"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test-success
spec:
  containers:
    - name: wget
      image: "busybox:latest"
      imagePullPolicy: "IfNotPresent"
      command: ['wget']
      args:  ['release-name-gitea-http:3000']
  restartPolicy: Never
